#!/usr/bin/env python3.5

import sys
import rdflib
from rdflib import Literal, Namespace

relation_count = {}

################################################################### helpers ####

def create_dummy_value ():
    global counter
    result = Literal('dummy_literal%d' % counter)
    counter += 1
    return result

###################################################################### main ####

# guard: commandline arguments
if len(sys.argv) != 4:
    print('Syntax: %s INPUT_FILENAME OUTPUT_FILENAME COMPLEXITY_FILENAME' % sys.argv[0])
    print('        %s ../../GroundTruth/building_instances/gtc_brick.ttl buildings/gth.ttl complexity_gth.txt' % sys.argv[0])
    print('        %s ../../ou44-brick/src/sdu_ou44_brick.ttl buildings/ou44.ttl complexity_ou44.txt' % sys.argv[0])
    exit()
ifilename = sys.argv[1]
ofilename = sys.argv[2]
cfilename = sys.argv[3]
counter = 1

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ initial

# load input
g = rdflib.Graph()
g.parse(ifilename, format='turtle')
relation_count['initial'] = len(g)

# load extension
g.parse('brick-data.ttl', format='turtle')
BD     = Namespace('https://brickschema.org/schema/1.0.1/BrickData#')
RDF    = Namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#')
RDFS   = Namespace('http://www.w3.org/2000/01/rdf-schema#')
BDPTS  = Namespace('http://mmmi.sdu.dk/1.0.1/buildings/ou44/bd_pt_s#')
g.bind('rdf'  , RDF)
g.bind('rdfs' , RDFS)
g.bind('bdpts', BDPTS)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ generic

DATA = Namespace('http://mmmi.sdu.dk/1.0.1/buildings/ou44/data#')
g.bind('data' , DATA)

# create archiver
archiver = DATA['archiver']
g.add( (archiver, RDF.type  , BD['SmapArchiver']) )
g.add( (archiver, BD.add    , create_dummy_value()) )
g.add( (archiver, BD.query  , create_dummy_value()) )
g.add( (archiver, BD.version, create_dummy_value()) )

relation_count['generic'] = len(g)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ lighting

BDPTL = Namespace('http://mmmi.sdu.dk/1.0.1/buildings/ou44/bd_pt_l#')
g.bind('bdptl', BDPTL)

# create lighting modeling approach
LightingApproach = BDPTL['Approach']
g.add( (LightingApproach, RDF.type, BD['Group']) )
LightingThresholdProperty = BDPTL['ThresholdProperty']
g.add( (LightingThresholdProperty, RDFS.subClassOf, BD['Property']) )
g.add( (LightingApproach, BD.contains, LightingThresholdProperty) )
#hasPropertyLightingThreshold = BDPTL['hasPropertyThreshold']
#g.add( (hasPropertyLightingThreshold, RDFS.subClassOf, BD['hasProperty']) )
LightingMaxOccupantsProperty = BDPTL['MaxOccupantsProperty']
g.add( (LightingMaxOccupantsProperty, RDFS.subClassOf, BD['Property']) )
g.add( (LightingApproach, BD.contains, LightingMaxOccupantsProperty) )
#hasPropertyLightingMaxOccupants = BDPTL['hasPropertyMaxOccupants']
#g.add( (hasPropertyLightingMaxOccupants, RDFS.subClassOf, BD['hasProperty']) )

# attach metering properties and streams
q = '''
SELECT ?meter
WHERE {
    ?meter rdf:type/rdfs:subClassOf* brick:Power_Meter .
}
'''
meters = sorted(g.query(q))
for row in meters:
    meter = row[0]
    
    # attach data stream
    data = DATA['meter/data%d' % counter]
    counter += 1
    g.add( (data, RDF.type       , BD['SmapData']) )
    g.add( (meter, BD.hasData, data) )
    g.add( (data, BD.uuid        , create_dummy_value()) )
    g.add( (data, BD.key         , create_dummy_value()) )
    g.add( (data, BD.hasArchiver , archiver) )
    
    # attach threshold property
    threshold_data = DATA['meter/threshold/data%d' % counter]
    counter += 1
    g.add( (threshold_data, RDF.type, BD['SmapData']) )
    threshold_prop = DATA['meter/threshold/property%d' % counter]
    counter += 1
    g.add( (threshold_prop, RDF.type, LightingMaxOccupantsProperty) )
    g.add( (meter, BD.hasProperty, threshold_prop) )
    g.add( (threshold_prop, BD.hasData     , threshold_data) )
    g.add( (threshold_data, BD.uuid        , create_dummy_value()) )
    g.add( (threshold_data, BD.key         , create_dummy_value()) )
    g.add( (threshold_data, BD.hasArchiver , archiver) )

# attach room properties
q = '''
SELECT ?room
WHERE {
    ?room rdf:type/rdfs:subClassOf* brick:Room .
}
'''
rooms = sorted(g.query(q))
for row in rooms:
    room = row[0]
    
    # attach maxOccupant property
    maxocc_data = DATA['room/maxocc/data%d' % counter]
    counter += 1
    g.add( (maxocc_data, RDF.type, BD['SmapData']) )
    maxocc_prop = DATA['room/maxocc/property%d' % counter]
    counter += 1
    g.add( (maxocc_prop, RDF.type, LightingThresholdProperty) )
    g.add( (room, BD.hasProperty, maxocc_prop) )
    g.add( (maxocc_prop, BD.hasData, maxocc_data) )
    g.add( (maxocc_data, BD.uuid        , create_dummy_value()) )
    g.add( (maxocc_data, BD.key         , create_dummy_value()) )
    g.add( (maxocc_data, BD.hasArchiver , archiver) )

relation_count['lighting'] = len(g)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ roomprediction

BDRP = Namespace('http://mmmi.sdu.dk/1.0.1/buildings/ou44/bd_rp#')
g.bind('bdrp' , BDRP)

# create room prediction approach
RoompredictionApproach = BDRP['Approach']
g.add( (RoompredictionApproach, RDF.type, BD['Group']) )

EwaProperty = BDRP['EwaProperty']
g.add( (EwaProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, EwaProperty) )
#hasPropertyRoompredictionEwa = BDRP['hasPropertyEwa']
#g.add( (hasPropertyRoompredictionEwa, RDFS.subClassOf, BD['hasProperty']) )

IlewtcProperty = BDRP['IlewtcProperty']
g.add( (IlewtcProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, IlewtcProperty) )
#hasPropertyRoompredictionIlewtc = BDRP['hasPropertyIlewtc']
#g.add( (hasPropertyRoompredictionIlewtc, RDFS.subClassOf, BD['hasProperty']) )

OlewtcProperty = BDRP['OlewtcProperty']
g.add( (OlewtcProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, OlewtcProperty) )
#hasPropertyRoompredictionOlewtc = BDRP['hasPropertyOlewtc']
#g.add( (hasPropertyRoompredictionOlewtc, RDFS.subClassOf, BD['hasProperty']) )

CO2Property = BDRP['CO2Property']
g.add( (CO2Property, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, CO2Property) )
#hasPropertyRoompredictionCO2 = BDRP['hasPropertyCO2']
#g.add( (hasPropertyRoompredictionCO2, RDFS.subClassOf, BD['hasProperty']) )

PcfProperty = BDRP['PcfProperty']
g.add( (PcfProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, PcfProperty) )
#hasPropertyRoompredictionPcf = BDRP['hasPropertyPcf']
#g.add( (hasPropertyRoompredictionPcf, RDFS.subClassOf, BD['hasProperty']) )

FpProperty = BDRP['FpProperty']
g.add( (FpProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, FpProperty) )
#hasPropertyRoompredictionFp = BDRP['hasPropertyFp']
#g.add( (hasPropertyRoompredictionFp, RDFS.subClassOf, BD['hasProperty']) )

OlewtrProperty = BDRP['OlewtrProperty']
g.add( (OlewtrProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, OlewtrProperty) )
#hasPropertyRoompredictionOlewtr = BDRP['hasPropertyOlewtr']
#g.add( (hasPropertyRoompredictionOlewtr, RDFS.subClassOf, BD['hasProperty']) )

MlewtrProperty = BDRP['MlewtrProperty']
g.add( (MlewtrProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, MlewtrProperty) )
#hasPropertyRoompredictionMlewtr = BDRP['hasPropertyMlewtr']
#g.add( (hasPropertyRoompredictionMlewtr, RDFS.subClassOf, BD['hasProperty']) )

ShProperty = BDRP['ShProperty']
g.add( (ShProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, ShProperty) )
#hasPropertyRoompredictionSh = BDRP['hasPropertySh']
#g.add( (hasPropertyRoompredictionSh, RDFS.subClassOf, BD['hasProperty']) )

TProperty = BDRP['TProperty']
g.add( (TProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, TProperty) )
#hasPropertyRoompredictionT = BDRP['hasPropertyT']
#g.add( (hasPropertyRoompredictionT, RDFS.subClassOf, BD['hasProperty']) )

CProperty = BDRP['CProperty']
g.add( (CProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, CProperty) )
#hasPropertyRoompredictionC = BDRP['hasPropertyC']
#g.add( (hasPropertyRoompredictionC, RDFS.subClassOf, BD['hasProperty']) )

IrProperty = BDRP['IrProperty']
g.add( (IrProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, IrProperty) )
#hasPropertyRoompredictionIr = BDRP['hasPropertyIr']
#g.add( (hasPropertyRoompredictionIr, RDFS.subClassOf, BD['hasProperty']) )

VProperty = BDRP['VProperty']
g.add( (VProperty, RDFS.subClassOf, BD['Property']) )
g.add( (RoompredictionApproach, BD.contains, VProperty) )
#hasPropertyRoompredictionV = BDRP['hasPropertyV']
#g.add( (hasPropertyRoompredictionV, RDFS.subClassOf, BD['hasProperty']) )

rp_map = {
    'ewa':    EwaProperty,
    'ilewtc': IlewtcProperty,
    'olewtc': OlewtcProperty,
    'co2':    CO2Property,
    'pcf':    PcfProperty,
    'fp':     FpProperty,
    'olewtr': OlewtrProperty,
    'mlewtr': MlewtrProperty,
    'sh':     ShProperty,
    't':      TProperty,
    'c':      CProperty,
    'ir':     IrProperty,
    'v':      VProperty,
}

relation_count['roomprediction.common'] = len(g)

# attach room properties
q = '''
SELECT ?room
WHERE {
    ?room rdf:type/rdfs:subClassOf* brick:Room .
}
'''
rooms = sorted(g.query(q))
for row in rooms:
    room = row[0]
    
    # attach bdrp:*
    for key in rp_map:
        prop_class = rp_map[key]
        data = DATA['room/%s/data%d' % (key, counter)]
        g.add( (data, RDF.type, BD['SmapData']) )
        counter += 1
        prop = DATA['room/%s/property%d' % (key, counter)]
        g.add( (prop, RDF.type, prop_class) )
        counter += 1
        g.add( (room, BD.hasProperty, prop) )
        g.add( (prop, BD.hasData, data) )
        g.add( (data, BD.uuid        , create_dummy_value()) )
        g.add( (data, BD.key         , create_dummy_value()) )
        g.add( (data, BD.hasArchiver , archiver) )

relation_count['roomprediction.rooms'] = len(g)

# attach temperature sensor streams
q = '''
SELECT ?temp
WHERE {
    ?temp rdf:type/rdfs:subClassOf* brick:Temperature_Sensor .
}
'''
temps = sorted(g.query(q))
for row in temps:
    temp = row[0]
    
    # attach data stream
    data = DATA['temp/data%d' % counter]
    counter += 1
    g.add( (data, RDF.type      , BD['SmapData']) )
    g.add( (temp, BD.hasData, data) )
    g.add( (data, BD.uuid, create_dummy_value()) )
    g.add( (data, BD.key , create_dummy_value()) )
    g.add( (data, BD.hasArchiver , archiver) )
    

relation_count['roomprediction.temp'] = len(g)

# attach co2 sensor streams
q = '''
SELECT ?co2
WHERE {
    ?co2 rdf:type/rdfs:subClassOf* brick:CO2_Sensor .
}
'''
co2s = sorted(g.query(q))
for row in co2s:
    co2 = row[0]
    
    # attach data stream
    data = DATA['temp/data%d' % counter]
    counter += 1
    g.add( (data, RDF.type      , BD['SmapData']) )
    g.add( (co2, BD.hasData, data) )
    g.add( (data, BD.uuid        , create_dummy_value()) )
    g.add( (data, BD.key         , create_dummy_value()) )
    g.add( (data, BD.hasArchiver , archiver) )

relation_count['roomprediction'] = len(g)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ write out

lines = []
lines.append('ifilename: %s' % ifilename)
lines.append('ofilename: %s' % ifilename)
lines.append('')
lines.append('inital: %u' % relation_count['initial'])
lines.append('generic: %u' % (relation_count['generic']-relation_count['initial']))
lines.append('lighting: %u' % (relation_count['lighting']-relation_count['generic']))
lines.append('roomprediction: %u' % (relation_count['roomprediction']-relation_count['lighting']))
lines.append('roomprediction.common: %u' % (relation_count['roomprediction.common']-relation_count['lighting']))
lines.append('roomprediction.rooms: %u (count: %u)' % (relation_count['roomprediction.rooms']-relation_count['roomprediction.common'], len(rooms)))
lines.append('roomprediction.temp: %u (count: %u)' % (relation_count['roomprediction.temp']-relation_count['roomprediction.rooms'], len(temps)))
lines.append('roomprediction.co2: %u (count: %u)' % (relation_count['roomprediction']-relation_count['roomprediction.temp'], len(co2s)))
with open(cfilename, 'w') as fo:
    fo.writelines(''.join(map(lambda line: '%s\n' % line, lines)))

# write output
g.serialize(ofilename, 'turtle')

